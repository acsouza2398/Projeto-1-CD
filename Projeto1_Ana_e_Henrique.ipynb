{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Ana Carolina\n",
    "\n",
    "Nome: Henrique Gabriel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo BaseDeDadosProjeto1.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'BaseDeDadosProjeto1.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Avaliação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@robsonbrito204 @isadorabasile mmmmeeeeeeu dee...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@emvideogame @xramoses @playstation_br com ess...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@eleitor73 @windowsclubbr playstation é forte ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@funimation_bra @ccxpoficial queria saber sobr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@fuck_off_matt eles vão ter que se acostumar c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Avaliação\n",
       "0  @robsonbrito204 @isadorabasile mmmmeeeeeeu dee...          3\n",
       "1  @emvideogame @xramoses @playstation_br com ess...          5\n",
       "2  @eleitor73 @windowsclubbr playstation é forte ...          1\n",
       "3  @funimation_bra @ccxpoficial queria saber sobr...          5\n",
       "4  @fuck_off_matt eles vão ter que se acostumar c...          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Avaliação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@facundini_ @izzynobre eles tem praticamente t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@traiinbe eu acho que se você é gamer hardcore...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@monstrohormonal @diegolt85 @playstation_br pe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normalmente quem prefere android prefere xbox\\...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>borderlands 3 será lançado para playstation 5 ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Avaliação\n",
       "0  @facundini_ @izzynobre eles tem praticamente t...          2\n",
       "1  @traiinbe eu acho que se você é gamer hardcore...          1\n",
       "2  @monstrohormonal @diegolt85 @playstation_br pe...          5\n",
       "3  normalmente quem prefere android prefere xbox\\...          5\n",
       "4  borderlands 3 será lançado para playstation 5 ...          5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "`Tendo em vista o Projeto 1 da matéria de Ciência de Dados, proposto pela Professora Maria Kelly Venezuela, escolhemos os produtos Xbox e PlayStation, os quais são marcas de consoles desenvolvidos pela Microsoft e pela Sony, respectivamente. \n",
    "    Logo, consideramos como \"não relevante\" qualquer tipo de postagem que usasse o @ desses produtos apenas para promover algo próprio, como por exemplo um canal no YouTube, ou qualquer tipo de postagem que embora utilizasse dos nomes dos produtos, não se relacionava com o mesmo. \n",
    "    Assim consideramos como \"relevante\" qualquer tipo de postagem que trata-se de certa forma a opinião sobre os produtos em questão.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Célula com função para limpar o DF\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[,!-.:?;/]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando o DF, transforando letras maiusculas em minusculas e passando o texto para uma lista de palavras\n",
    "\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "todas_as_palavras_ps = []\n",
    "todas_as_palavras_indi = []\n",
    "todas_as_palavras_xbox = []\n",
    "todas_as_palavras_irr = []\n",
    "\n",
    "for i, texto in enumerate(train.Treinamento):\n",
    "    \n",
    "    texto = cleanup(str(texto).lower())\n",
    "    \n",
    "    if train.Avaliação[i] == 5:\n",
    "        todas_as_palavras_irr += (tweet_tokenizer.tokenize(texto))\n",
    "    \n",
    "    elif train.Avaliação[i] == 1: \n",
    "        todas_as_palavras_ps += (tweet_tokenizer.tokenize(texto))\n",
    "    \n",
    "    elif train.Avaliação[i] == 2: \n",
    "        todas_as_palavras_indi += (tweet_tokenizer.tokenize(texto))\n",
    "    \n",
    "    else:\n",
    "        todas_as_palavras_xbox += (tweet_tokenizer.tokenize(texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LISTA COM PALAVRAS COMUNS QUE PODEM SER \"LIMPADAS\" DO DF \n",
    "\n",
    "palavras_desnecessarias = [\"a\", \"o\", \"e\", \"da\", \"do\", \"em\", \"dos\", \"das\", \"que\", \"de\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['esse',\n",
       " 'reajuste',\n",
       " 'serviços',\n",
       " 'xbox',\n",
       " 'dá',\n",
       " 'mesmo',\n",
       " 'total',\n",
       " 'você',\n",
       " 'assinava']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#limpando @'s dos usuarios e palavras desnecessarias\n",
    "\n",
    "todas_as_palavras_irr_arroba = []\n",
    "\n",
    "for num, palavra in enumerate(todas_as_palavras_irr):\n",
    "    if (\"@\" not in palavra) and (palavra not in palavras_desnecessarias):\n",
    "        todas_as_palavras_irr_arroba.append(palavra)\n",
    "\n",
    "todas_as_palavras_irr_arroba[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['playstation',\n",
       " 'é',\n",
       " 'forte',\n",
       " 'no',\n",
       " 'mercado',\n",
       " 'europeu',\n",
       " 'asiático',\n",
       " 'também',\n",
       " 'tem',\n",
       " 'uma']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#limpando @'s dos usuarios e palavras desnecessarias\n",
    "\n",
    "todas_as_palavras_ps_arroba = []\n",
    "\n",
    "for num, palavra in enumerate(todas_as_palavras_ps):\n",
    "    if (\"@\" not in palavra) and (palavra not in palavras_desnecessarias):\n",
    "        todas_as_palavras_ps_arroba.append(palavra)\n",
    "\n",
    "todas_as_palavras_ps_arroba[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conversando',\n",
       " 'com',\n",
       " 'um',\n",
       " 'amigo',\n",
       " 'cheguei',\n",
       " 'conclusão',\n",
       " 'na',\n",
       " 'década',\n",
       " '90',\n",
       " 'os']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#limpando @'s dos usuarios e palavras desnecessarias\n",
    "\n",
    "todas_as_palavras_indi_arroba = []\n",
    "\n",
    "for num, palavra in enumerate(todas_as_palavras_indi):\n",
    "    if (\"@\" not in palavra) and (palavra not in palavras_desnecessarias):\n",
    "        todas_as_palavras_indi_arroba.append(palavra)\n",
    "\n",
    "todas_as_palavras_indi_arroba[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mmmmeeeeeeu',\n",
       " 'deeeeeeeeeeeeeeeuuuussss',\n",
       " 'retardado',\n",
       " 'joga',\n",
       " 'playstation',\n",
       " 'quer',\n",
       " 'exigir',\n",
       " 'uma',\n",
       " 'gtgtgt',\n",
       " 'apresentadora']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#limpando @'s dos usuarios e palavras desnecessarias\n",
    "\n",
    "todas_as_palavras_xbox_arroba = []\n",
    "\n",
    "for num, palavra in enumerate(todas_as_palavras_xbox):\n",
    "    if (\"@\" not in palavra) and (palavra not in palavras_desnecessarias):\n",
    "        todas_as_palavras_xbox_arroba.append(palavra)\n",
    "\n",
    "todas_as_palavras_xbox_arroba[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando lista em um Series\n",
    "\n",
    "serie_palavras_irr = pd.Series(todas_as_palavras_irr_arroba)\n",
    "\n",
    "serie_palavras_ps = pd.Series(todas_as_palavras_ps_arroba)\n",
    "\n",
    "serie_palavras_indi = pd.Series(todas_as_palavras_indi_arroba)\n",
    "\n",
    "serie_palavras_xbox = pd.Series(todas_as_palavras_xbox_arroba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xbox            0.039558\n",
       "playstation     0.035638\n",
       "para            0.016037\n",
       "4               0.013186\n",
       "rt              0.011761\n",
       "                  ...   \n",
       "baseado         0.000356\n",
       "httpstcoklky    0.000356\n",
       "edition         0.000356\n",
       "contas          0.000356\n",
       "museu           0.000356\n",
       "Length: 1218, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adquirindo a tabela de frequências relativas a partir de um dos Series criados acima\n",
    "\n",
    "tabela_tweets_relativa_irr = serie_palavras_irr.value_counts(True)\n",
    "tabela_tweets_relativa_irr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xbox           0.041178\n",
       "playstation    0.029189\n",
       "não            0.024759\n",
       "é              0.024238\n",
       "mais           0.017462\n",
       "                 ...   \n",
       "modelo         0.000261\n",
       "líder          0.000261\n",
       "acredita       0.000261\n",
       "inclusive      0.000261\n",
       "refere         0.000261\n",
       "Length: 1288, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adquirindo a tabela de frequências relativas a partir de um dos Series criados acima\n",
    "\n",
    "tabela_tweets_relativa_ps = serie_palavras_ps.value_counts(True)\n",
    "tabela_tweets_relativa_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xbox               0.042702\n",
       "playstation        0.036752\n",
       "não                0.017151\n",
       "é                  0.016801\n",
       "no                 0.014701\n",
       "                     ...   \n",
       "informações        0.000350\n",
       "sonyplaystation    0.000350\n",
       "0mewtc4tl0         0.000350\n",
       "joão               0.000350\n",
       "inovou             0.000350\n",
       "Length: 1135, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adquirindo a tabela de frequências relativas a partir de um dos Series criados acima\n",
    "\n",
    "tabela_tweets_relativa_indi = serie_palavras_indi.value_counts(True)\n",
    "tabela_tweets_relativa_indi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xbox           0.044807\n",
       "playstation    0.030259\n",
       "é              0.029095\n",
       "não            0.021239\n",
       "mais           0.018039\n",
       "                 ...   \n",
       "criei          0.000291\n",
       "199999         0.000291\n",
       "cachorro       0.000291\n",
       "ps3            0.000291\n",
       "companhia      0.000291\n",
       "Length: 1179, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adquirindo a tabela de frequências relativas a partir de um dos Series criados acima\n",
    "\n",
    "tabela_tweets_relativa_xbox = serie_palavras_xbox.value_counts(True)\n",
    "tabela_tweets_relativa_xbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpando o DF, transforando letras maiusculas em minusculas e passando o texto para uma lista de palavras que representaram o conjunto LÍNGUA PORTUGUESA\n",
    "\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "todas_as_palavras_test = []\n",
    "\n",
    "for texto in test.Teste:\n",
    "    texto = cleanup(str(texto).lower())\n",
    "    todas_as_palavras_test += (tweet_tokenizer.tokenize(texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xbox               0.042127\n",
       "playstation        0.032542\n",
       "é                  0.019634\n",
       "não                0.017778\n",
       "mais               0.014145\n",
       "                     ...   \n",
       "httpstcofgagoxg    0.000077\n",
       "tchola             0.000077\n",
       "9d5ew              0.000077\n",
       "concorrendo        0.000077\n",
       "httpstcoovtyy      0.000077\n",
       "Length: 3310, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transformando lista em um Series e adquirindo a tabela de frequências relativas a partir de um mesmo Series.\n",
    "\n",
    "portugues = todas_as_palavras_irr + todas_as_palavras_ps + todas_as_palavras_indi + todas_as_palavras_xbox\n",
    "\n",
    "#limpando @'s dos usuarios e palavras desnecessarias\n",
    "\n",
    "portugues_arroba = []\n",
    "\n",
    "for num, palavra in enumerate(portugues):\n",
    "    if (\"@\" not in palavra) and (palavra not in palavras_desnecessarias):\n",
    "        portugues_arroba.append(palavra)\n",
    "\n",
    "\n",
    "serie_portugues = pd.Series(portugues_arroba)\n",
    "tabela_portugues_relativa = serie_portugues.value_counts(True)\n",
    "tabela_portugues_relativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividindo entre Relevante ou Não Relevante de acordo com nossos critérios e nossas considerações\n",
    "\n",
    "train.loc[(train.Avaliação == 5),\"Rel_Or_Not\"] = 'Not relevant'\n",
    "train.loc[(train.Avaliação == 1),\"Rel_Or_Not\"] = 'Relevant'\n",
    "train.loc[(train.Avaliação == 2),'Rel_Or_Not'] = 'Relevant'\n",
    "train.loc[(train.Avaliação == 3),'Rel_Or_Not'] = 'Relevant'\n",
    "\n",
    "test.loc[(test.Avaliação == 5),\"Rel_Or_Not\"] = 'Not relevant'\n",
    "test.loc[(test.Avaliação == 1),\"Rel_Or_Not\"] = 'Relevant'\n",
    "test.loc[(test.Avaliação == 2),'Rel_Or_Not'] = 'Relevant'\n",
    "test.loc[(test.Avaliação == 3),'Rel_Or_Not'] = 'Relevant'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probPS: 0.2594594594594595\n",
      "probINDI: 0.22882882882882882\n",
      "probXBOX: 0.25045045045045045\n",
      "probIRRE: 0.26126126126126126\n"
     ]
    }
   ],
   "source": [
    "# Calculando as probabilidades relativas de cada categoria \n",
    "\n",
    "prob_rel_or_not = train.Avaliação.value_counts(True, sort=False)\n",
    "\n",
    "probPS = prob_rel_or_not[1]\n",
    "probINDI = prob_rel_or_not[2]\n",
    "probXBOX =  prob_rel_or_not[3]\n",
    "probIRRE =  prob_rel_or_not[5]\n",
    "\n",
    "\n",
    "print(\"probPS:\",probPS)\n",
    "print(\"probINDI:\",probINDI)\n",
    "print(\"probXBOX:\",probXBOX)\n",
    "print(\"probIRRE:\",probIRRE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULANDO A PROBABILIDADE DE UM TWEET (USANDO SUAVIZAÇÃO LA PLACE)\n",
    "\n",
    "for n, tweet in enumerate(test.Teste):\n",
    "\n",
    "    prob_tweet = 0\n",
    "\n",
    "    tweet = cleanup(str(tweet).lower())\n",
    "    tweet = tweet.split()\n",
    "\n",
    "    for i, word in enumerate(tweet):\n",
    "        if (word in todas_as_palavras_irr_arroba) or (word in todas_as_palavras_ps_arroba) or (word in todas_as_palavras_indi_arroba) or (word in todas_as_palavras_xbox_arroba):\n",
    "            if prob_tweet == 0:\n",
    "                prob_tweet = (tabela_portugues_relativa[word] + 1)\n",
    "            else:\n",
    "                prob_tweet = prob_tweet * (tabela_portugues_relativa[word] + 1)\n",
    "\n",
    "    test.loc[n,'ProbTweet'] = prob_tweet / (i + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULANDO A PROBABILIDADE DE UM TWEET DADO QUE É IRRELEVANTE (USANDO SUAVIZAÇÃO DE LA PLACE)\n",
    "\n",
    "for n, tweet in enumerate(test.Teste):\n",
    "\n",
    "    prob_tweet = 0\n",
    "\n",
    "    tweet = cleanup(str(tweet).lower())\n",
    "    tweet = tweet.split()\n",
    "\n",
    "    for i, word in enumerate(tweet):\n",
    "        if word in todas_as_palavras_irr_arroba:\n",
    "            if prob_tweet == 0:\n",
    "                prob_tweet = (tabela_tweets_relativa_irr[word] + 1)\n",
    "            else:\n",
    "                prob_tweet = prob_tweet * (tabela_tweets_relativa_irr[word] + 1)\n",
    "        else:\n",
    "            if prob_tweet == 0:\n",
    "                prob_tweet = 1\n",
    "            else:\n",
    "                prob_tweet = prob_tweet\n",
    "        \n",
    "    test.loc[n,'ProbTweet_IRR'] = prob_tweet / (i + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULANDO A PROBABILIDADE DE UM TWEET DADO QUE PLAYSTATION É A CATEGORIA (USANDO SUAVIZAÇÃO DE LA PLACE)\n",
    "\n",
    "for n, tweet in enumerate(test.Teste):\n",
    "\n",
    "    prob_tweet = 0\n",
    "\n",
    "    tweet = cleanup(str(tweet).lower())\n",
    "    tweet = tweet.split()\n",
    "\n",
    "    for i, word in enumerate(tweet):\n",
    "        if word in todas_as_palavras_ps_arroba:\n",
    "            if prob_tweet == 0:\n",
    "                prob_tweet = (tabela_tweets_relativa_ps[word] + 1)\n",
    "            else:\n",
    "                prob_tweet = prob_tweet * (tabela_tweets_relativa_ps[word] + 1)\n",
    "        else:\n",
    "            if prob_tweet == 0:\n",
    "                prob_tweet = 1\n",
    "            else:\n",
    "                prob_tweet = prob_tweet\n",
    "        \n",
    "    test.loc[n,'ProbTweet_PS'] = prob_tweet / (i + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULANDO A PROBABILIDADE DE UM TWEET DADO QUE É INDIFERENTE (USANDO SUAVIZAÇÃO DE LA PLACE)\n",
    "\n",
    "for n, tweet in enumerate(test.Teste):\n",
    "\n",
    "    prob_tweet = 0\n",
    "\n",
    "    tweet = cleanup(str(tweet).lower())\n",
    "    tweet = tweet.split()\n",
    "\n",
    "    for i, word in enumerate(tweet):\n",
    "        if word in todas_as_palavras_indi_arroba:\n",
    "            if prob_tweet == 0:\n",
    "                prob_tweet = (tabela_tweets_relativa_indi[word] + 1)\n",
    "            else:\n",
    "                prob_tweet = prob_tweet * (tabela_tweets_relativa_indi[word] + 1)\n",
    "        else:\n",
    "            if prob_tweet == 0:\n",
    "                prob_tweet = 1\n",
    "            else:\n",
    "                prob_tweet = prob_tweet\n",
    "        \n",
    "    test.loc[n,'ProbTweet_INDI'] = prob_tweet / (i + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULANDO A PROBABILIDADE DE UM TWEET DADO QUE XBOX É A CATEGORIA (USANDO SUAVIZAÇÃO DE LA PLACE)\n",
    "\n",
    "for n, tweet in enumerate(test.Teste):\n",
    "\n",
    "    prob_tweet = 0\n",
    "\n",
    "    tweet = cleanup(str(tweet).lower())\n",
    "    tweet = tweet.split()\n",
    "\n",
    "    for i, word in enumerate(tweet):\n",
    "        if word in todas_as_palavras_xbox_arroba:\n",
    "            if prob_tweet == 0:\n",
    "                prob_tweet = (tabela_tweets_relativa_xbox[word] + 1)\n",
    "            else:\n",
    "                prob_tweet = prob_tweet * (tabela_tweets_relativa_xbox[word] + 1)\n",
    "        else:\n",
    "            if prob_tweet == 0:\n",
    "                prob_tweet = 1\n",
    "            else:\n",
    "                prob_tweet = prob_tweet\n",
    "        \n",
    "    test.loc[n,'ProbTweet_XBOX'] = prob_tweet / (i + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-7c97ba5537d3>:4: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_irr_dado_tweet = test.loc[n, 'ProbTweet_IRR'] * probIRRE / test.loc[n, 'ProbTweet']\n",
      "<ipython-input-26-7c97ba5537d3>:5: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_ps_dado_tweet = test.loc[n, 'ProbTweet_PS'] * probPS / test.loc[n, 'ProbTweet']\n",
      "<ipython-input-26-7c97ba5537d3>:6: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_indi_dado_tweet = test.loc[n, 'ProbTweet_INDI'] * probINDI / test.loc[n, 'ProbTweet']\n",
      "<ipython-input-26-7c97ba5537d3>:7: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  prob_xbox_dado_tweet = test.loc[n, 'ProbTweet_XBOX'] * probXBOX / test.loc[n, 'ProbTweet']\n"
     ]
    }
   ],
   "source": [
    "#APLICANDO NAIVE BAYES PARA OS TWEETS CONSIDERANDO APENAS RELEVANTE OU IRRELEVANTE\n",
    "for n, tweet in enumerate(test.Teste):\n",
    "    \n",
    "    prob_irr_dado_tweet = test.loc[n, 'ProbTweet_IRR'] * probIRRE / test.loc[n, 'ProbTweet']\n",
    "    prob_ps_dado_tweet = test.loc[n, 'ProbTweet_PS'] * probPS / test.loc[n, 'ProbTweet']\n",
    "    prob_indi_dado_tweet = test.loc[n, 'ProbTweet_INDI'] * probINDI / test.loc[n, 'ProbTweet']\n",
    "    prob_xbox_dado_tweet = test.loc[n, 'ProbTweet_XBOX'] * probXBOX / test.loc[n, 'ProbTweet']\n",
    "\n",
    "    lista_para_ver_maior_prob = [prob_irr_dado_tweet, prob_ps_dado_tweet, prob_indi_dado_tweet, prob_xbox_dado_tweet]\n",
    "\n",
    "    if max(lista_para_ver_maior_prob) == prob_irr_dado_tweet:\n",
    "        test.loc[n,\"ClassByCategoria\"] = \"Not relevant\"\n",
    "        test.loc[n,\"ClassByRelevancia\"] = \"Not relevant\"\n",
    "    \n",
    "    elif max(lista_para_ver_maior_prob) == prob_ps_dado_tweet:\n",
    "        test.loc[n,\"ClassByCategoria\"] = \"PlayStation\"\n",
    "        test.loc[n,\"ClassByRelevancia\"] = \"Relevant\"     \n",
    "    \n",
    "    elif max(lista_para_ver_maior_prob) == prob_indi_dado_tweet:\n",
    "        test.loc[n,\"ClassByCategoria\"] = \"Indifferent\"\n",
    "        test.loc[n,\"ClassByRelevancia\"] = \"Relevant\"\n",
    "    \n",
    "    else:\n",
    "        test.loc[n,\"ClassByCategoria\"] = \"Xbox\"\n",
    "        test.loc[n,\"ClassByRelevancia\"] = \"Relevant\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Avaliação</th>\n",
       "      <th>Rel_Or_Not</th>\n",
       "      <th>ProbTweet</th>\n",
       "      <th>ProbTweet_IRR</th>\n",
       "      <th>ProbTweet_PS</th>\n",
       "      <th>ProbTweet_INDI</th>\n",
       "      <th>ProbTweet_XBOX</th>\n",
       "      <th>ClassByCategoria</th>\n",
       "      <th>ClassByRelevancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@facundini_ @izzynobre eles tem praticamente t...</td>\n",
       "      <td>2</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>0.024528</td>\n",
       "      <td>0.022467</td>\n",
       "      <td>0.025468</td>\n",
       "      <td>0.024551</td>\n",
       "      <td>0.025231</td>\n",
       "      <td>PlayStation</td>\n",
       "      <td>Relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@traiinbe eu acho que se você é gamer hardcore...</td>\n",
       "      <td>1</td>\n",
       "      <td>Relevant</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.030118</td>\n",
       "      <td>0.032464</td>\n",
       "      <td>0.031863</td>\n",
       "      <td>0.032629</td>\n",
       "      <td>PlayStation</td>\n",
       "      <td>Relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@monstrohormonal @diegolt85 @playstation_br pe...</td>\n",
       "      <td>5</td>\n",
       "      <td>Not relevant</td>\n",
       "      <td>0.036927</td>\n",
       "      <td>0.036724</td>\n",
       "      <td>0.036944</td>\n",
       "      <td>0.036832</td>\n",
       "      <td>0.037152</td>\n",
       "      <td>Not relevant</td>\n",
       "      <td>Not relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normalmente quem prefere android prefere xbox\\...</td>\n",
       "      <td>5</td>\n",
       "      <td>Not relevant</td>\n",
       "      <td>0.083279</td>\n",
       "      <td>0.083259</td>\n",
       "      <td>0.082945</td>\n",
       "      <td>0.083564</td>\n",
       "      <td>0.083429</td>\n",
       "      <td>Not relevant</td>\n",
       "      <td>Not relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>borderlands 3 será lançado para playstation 5 ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Not relevant</td>\n",
       "      <td>0.085410</td>\n",
       "      <td>0.087278</td>\n",
       "      <td>0.083834</td>\n",
       "      <td>0.086648</td>\n",
       "      <td>0.084648</td>\n",
       "      <td>Not relevant</td>\n",
       "      <td>Not relevant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Avaliação    Rel_Or_Not  \\\n",
       "0  @facundini_ @izzynobre eles tem praticamente t...          2      Relevant   \n",
       "1  @traiinbe eu acho que se você é gamer hardcore...          1      Relevant   \n",
       "2  @monstrohormonal @diegolt85 @playstation_br pe...          5  Not relevant   \n",
       "3  normalmente quem prefere android prefere xbox\\...          5  Not relevant   \n",
       "4  borderlands 3 será lançado para playstation 5 ...          5  Not relevant   \n",
       "\n",
       "   ProbTweet  ProbTweet_IRR  ProbTweet_PS  ProbTweet_INDI  ProbTweet_XBOX  \\\n",
       "0   0.024528       0.022467      0.025468        0.024551        0.025231   \n",
       "1   0.031856       0.030118      0.032464        0.031863        0.032629   \n",
       "2   0.036927       0.036724      0.036944        0.036832        0.037152   \n",
       "3   0.083279       0.083259      0.082945        0.083564        0.083429   \n",
       "4   0.085410       0.087278      0.083834        0.086648        0.084648   \n",
       "\n",
       "  ClassByCategoria ClassByRelevancia  \n",
       "0      PlayStation          Relevant  \n",
       "1      PlayStation          Relevant  \n",
       "2     Not relevant      Not relevant  \n",
       "3     Not relevant      Not relevant  \n",
       "4     Not relevant      Not relevant  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ClassByRelevancia</th>\n",
       "      <th>Not relevant</th>\n",
       "      <th>Relevant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rel_Or_Not</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not relevant</th>\n",
       "      <td>63</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevant</th>\n",
       "      <td>28</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ClassByRelevancia  Not relevant  Relevant\n",
       "Rel_Or_Not                               \n",
       "Not relevant                 63        25\n",
       "Relevant                     28       161"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.Rel_Or_Not, test.ClassByRelevancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ClassByRelevancia</th>\n",
       "      <th>Not relevant</th>\n",
       "      <th>Relevant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rel_Or_Not</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Not relevant</th>\n",
       "      <td>71.590909</td>\n",
       "      <td>28.409091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevant</th>\n",
       "      <td>14.814815</td>\n",
       "      <td>85.185185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ClassByRelevancia  Not relevant   Relevant\n",
       "Rel_Or_Not                                \n",
       "Not relevant          71.590909  28.409091\n",
       "Relevant              14.814815  85.185185"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test.Rel_Or_Not, test.ClassByRelevancia, normalize = \"index\")*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O modelo classificou corretamente 80.87% dos dados de teste.\n",
      "O modelo classificou errado 19.13% dos dados de teste. \n",
      "\n",
      "---------------------- \n",
      "\n",
      "O modelo teve 58.12% de verdadeiros positivos. \n",
      "O modelo teve 22.74% de verdadeiros negativos. \n",
      "O modelo teve 10.11% de falsos positivos. \n",
      "O modelo teve 9.03% de falsos negativos. \n",
      "\n",
      "---------------------- \n",
      "\n",
      "Foram classificados manualmente 68.23% tweets relevantes e 31.77% tweets irrelevantes. \n",
      "Foram classificados pelo algoritmo 67.15% tweets relevantes e 32.85% tweets irrelevantes.\n"
     ]
    }
   ],
   "source": [
    "# anali1 = test.Rel_Or_Not == \"Indifferent\"\n",
    "# anali2 = test.Rel_Or_Not == \"Not relevant\"\n",
    "# anali3 = test.Rel_Or_Not == \"PlayStation\"\n",
    "# anali4 = test.Rel_Or_Not == \"Xbox\"\n",
    "\n",
    "# resul1 = test.ClassByCategoria == \"Indifferent\"\n",
    "# resul2 = test.ClassByCategoria == \"Not relevant\"\n",
    "# resul3 = test.ClassByCategoria == \"PlayStation\"\n",
    "# resul4 = test.ClassByCategoria == \"Xbox\"\n",
    "\n",
    "# acerto_indi = test.loc[anali1 & resul1, :]\n",
    "# acerto_irre = test.loc[anali2 & resul2, :]\n",
    "# acerto_ps = test.loc[anali3 & resul3, :]\n",
    "# acerto_xbox = test.loc[anali4 & resul4, :]\n",
    "\n",
    "anali1 = test.Rel_Or_Not == \"Relevant\"\n",
    "anali2 = test.Rel_Or_Not == \"Not relevant\"\n",
    "\n",
    "resul1 = test.ClassByRelevancia == \"Relevant\"\n",
    "resul2 = test.ClassByRelevancia == \"Not relevant\"\n",
    "\n",
    "acerto_rele = test.loc[anali1 & resul1, :]\n",
    "acerto_irre = test.loc[anali2 & resul2, :]\n",
    "erro_rele = test.loc[anali1 & resul2, :]\n",
    "erro_irre = test.loc[anali2 & resul1, :]\n",
    "\n",
    "acerto = (len(acerto_rele) + len(acerto_irre))/len(test)*100      \n",
    "print(f\"O modelo classificou corretamente {acerto :.2f}% dos dados de teste.\")\n",
    "\n",
    "erro = 100 - acerto  \n",
    "print(f\"O modelo classificou errado {erro :.2f}% dos dados de teste. \\n\")\n",
    "\n",
    "print(\"---------------------- \\n\")\n",
    "\n",
    "verd_pos = len(acerto_rele)/len(test)*100\n",
    "print(f\"O modelo teve {verd_pos :.2f}% de verdadeiros positivos. \")\n",
    "\n",
    "verd_neg = len(acerto_irre)/len(test)*100\n",
    "print(f\"O modelo teve {verd_neg :.2f}% de verdadeiros negativos. \")\n",
    "\n",
    "fal_pos = len(erro_rele)/len(test)*100\n",
    "print(f\"O modelo teve {fal_pos :.2f}% de falsos positivos. \")\n",
    "\n",
    "fal_neg = len(erro_irre)/len(test)*100\n",
    "print(f\"O modelo teve {fal_neg :.2f}% de falsos negativos. \\n\")\n",
    "\n",
    "print(\"---------------------- \\n\")\n",
    "\n",
    "class_mao_rele = len(test.loc[anali1, :])/len(test)*100\n",
    "class_mao_irre = len(test.loc[anali2, :])/len(test)*100\n",
    "print(f\"Foram classificados manualmente {class_mao_rele :.2f}% tweets relevantes e {class_mao_irre :.2f}% tweets irrelevantes. \")\n",
    "\n",
    "class_bayes_rele = len(test.loc[resul1, :])/len(test)*100\n",
    "class_bayes_irre = len(test.loc[resul2, :])/len(test)*100\n",
    "print(f\"Foram classificados pelo algoritmo {class_bayes_rele :.2f}% tweets relevantes e {class_bayes_irre :.2f}% tweets irrelevantes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    O modelo classificou corretamente 80.87% dos dados de teste, dando um erro de 19.13%. O grupo julgou isso como um erro baixo, mas que pode ainda ser abaixado. Um fator que pode ter piorado o rendimento do classificador é erros de escrita, palavras exageradamente alongadas como \"kkkkkkkk\" ou \"meeeeeeeeu deeeeeeeeus\", esses dois sendo exemplos que apareceram na base de dados. Isso causa mais uma entrada no vocabulário do algoritmo e pode levar a um viés na classificação, visto que é improvavel que irão aparecer novamente.\n",
    "    \n",
    "    Uma possível saída para isso seria usar um corretor de texto para limpar esses erros e melhorar a qualidade da base de dados, além da remoção dos nomes dos usuários, algo que já foi implementado no código.\n",
    "    \n",
    "    O Naive-Bayes é um classificador com alto viés e baixa variância. Para diminuir esse viés, seria possível aplicar Boosting. Boosting se baseia nos erros feitos no modelo e, ao atribuir pesos maiores a esses erros, treina um novo modelo. Esse aprendizado incremental baseado nos erros leva a um modelo mais bem treinado para os evitar e diminuindo o seu viés. Ele não é um modelo em si, e sim um jeito de melhorar um classificador e propor um modelo mais eficaz. Um estudo feito pela Universidade de San Diego, na California, sustenta o uso de Boosting para melhorar a performance do classificador Naive-Bayes. Há bibliotecas no Python que já tem algoritmos de Boosting disponíveis, como o próprio sklearn que usamos em aula, de onde seria possível importar o AdaBoostClassifier, o mais popular algoritmo de Boosting.\n",
    "    \n",
    "    Outra opção seria usar log para fazer a comparação das probabilidades. Como o Naive-Bayes trabalha com a comparação de probabilidades, isso não iria afetar a classificação do modelo. O log iria resolver um problema computacional que o Naive-Bayes pode encontrar. À medida que o vocabulário do modelo vai crescendo, as probabilidades vão de aproximando de zero. Isso acontece porque várias pequenas probabilidades multiplicadas para formar a probabilidade da frase vão gerar um número menor ainda. Dependendo do tamanho gerado, o computador pode não conseguir usar double nem long double para armazenar a probabilidade. Esse problema de números muito pequenos foi observado na célula 26 desse arquivo. Para evitar isso, o log pode ser implementado. Como, diferentemente de probabilidades, o log-probabilidade gera números entre menos infinito e 0, ele é mais facilmente computado. Para implementar isso, basta calcular ln P(palavra|vocabulário) ao invés de P(palavra|vocabulário).\n",
    "    \n",
    "    Não é possível alimentar a base de treinamento usando o próprio classificador. O classificador vai classificar os tweets e vai cometer erros, seja eles positivos falsos ou negativos falsos. Ao alimentar o classificador com os seus dados, os tweets errados vão treinar o algoritmo errado, aumentando a quantidade de erros que ele irá cometer. Como o intuito é diminuir os erros, alimentar a base de treinamento com tweets classificados pelo algoritmo seria contraintuitivo.\n",
    "\n",
    "    O algoritmo do Naive-Bayes tem alta acurácia em classificações de eventos independentes e, para isso, pode ser aplicado em outras situações como classificar e-mails em spam vs ham, dado uma base de dados de e-mails; considerando a quantidade de itens comprados e o valor final da compra, qual a probabilidade de o cliente ter pagado usando cartão ou dinheiro; classificar fake news e real news, dado uma base de dados de artigos.\n",
    "\n",
    "    O projeto ainda tem algumas mudanças possíveis, como as sugeridas acima, para aumentar a sua porcentagem de acerto. Com isso, vale o investimento para continuar o projeto e implementar essas mudanças para melhorar o classificador e o tornar mais útil à área de marketing da empresa. Como a porcentagem de acerto foi boa, ao melhorar a performance do algoritmo, ele poderá ser uma ferramenta importante para julgar opiniões sobre os usuários do produto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências usadas pelo grupo\n",
    "[Using Log-Probabilities for Naive Bayes](http://www.cs.rhodes.edu/~kirlinp/courses/ai/f18/projects/proj3/naive-bayes-log-probs.pdf)\n",
    "\n",
    "[Naive Bayesian Model](https://acadgild.com/blog/naive-bayesian-model)\n",
    "\n",
    "[Boosting and Naive Bayesian Learning](http://pages.cs.wisc.edu/~dyer/cs540/handouts/elkan97boosting.pdf)\n",
    "\n",
    "[A Guide to AdaBoost: Boosting To Save The Day](https://blog.paperspace.com/adaboost-optimizer/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* `Limpar: \\n, :, \", ', (, ), etc SEM remover emojis`\n",
    "* `Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis`\n",
    "* `Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação`\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* `Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento`\n",
    "* `Propor diferentes cenários para Naïve Bayes fora do contexto do projeto`\n",
    "* `Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)`\n",
    "* Montar um dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
